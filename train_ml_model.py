"""
MOTOR FAULT DIAGNOSIS - ML TRAINING (CORRECTED)
================================================
Trains on extract_features.csv — same 19 features as dashboard.py
Pipeline: MATLAB extract_features.m → extract_features.csv → this script → ml_model.pkl
"""

import pandas as pd
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

print("=" * 60)
print("MOTOR FAULT DIAGNOSIS - ML TRAINING")
print("=" * 60)

# ===== CONFIGURATION =====
# Put extract_features.csv in the same folder as this script
CSV_PATH    = 'extract_features.csv'   # generated by MATLAB extract_features.m
MODEL_OUT   = 'ml_model.pkl'
FEATURES_OUT= 'features.pkl'

# ===== STEP 1: LOAD FEATURES CSV =====
print(f"\nLooking for: {CSV_PATH}")

if not os.path.exists(CSV_PATH):
    print("\n❌ ERROR: extract_features.csv not found!")
    print("\nYou need to run MATLAB first:")
    print("  >> run extract_features.m")
    print("Then copy extract_features.csv to this folder.")
    exit()

df = pd.read_csv(CSV_PATH)
print(f"✅ Loaded extract_features.csv")
print(f"   Rows    : {len(df):,}  (one row = one motor recording)")
print(f"   Columns : {list(df.columns)}")

# ===== STEP 2: SPLIT FEATURES AND LABEL =====
print("\n" + "=" * 60)
print("PREPARING DATA...")
print("=" * 60)

# All columns except 'label' are features — same 19 as extract_features.m
feature_cols = [c for c in df.columns if c != 'label']
X = df[feature_cols].values
y = df['label'].values

print(f"\nFeatures ({len(feature_cols)}):")
for i, f in enumerate(feature_cols, 1):
    print(f"  {i:2d}. {f}")

print(f"\nClass distribution:")
for lbl, name in enumerate(['Healthy', 'Voltage Unbalance', 'Rotor Fault', 'Stator Fault']):
    count = int(np.sum(y == lbl))
    print(f"  {lbl} - {name:<20}: {count:,} samples")

# ===== STEP 3: TRAIN / TEST SPLIT =====
print("\n" + "=" * 60)
print("SPLITTING DATA (70% train / 30% test)...")
print("=" * 60)

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,
    random_state=42,
    stratify=y        # keep class balance in both splits
)

print(f"Training samples : {len(X_train):,}")
print(f"Testing  samples : {len(X_test):,}")

# ===== STEP 4: TRAIN RANDOM FOREST =====
print("\n" + "=" * 60)
print("TRAINING RANDOM FOREST (150 trees)...")
print("=" * 60)

model = RandomForestClassifier(
    n_estimators=150,
    max_depth=None,     # grow full trees — good for clean simulation data
    random_state=42,
    n_jobs=-1           # use all CPU cores
)

model.fit(X_train, y_train)
print("✅ Training complete!")

# ===== STEP 5: EVALUATE =====
print("\n" + "=" * 60)
print("EVALUATING MODEL...")
print("=" * 60)

y_pred   = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred) * 100

print(f"\n{'=' * 60}")
print(f"  ACCURACY: {accuracy:.2f}%")
print(f"{'=' * 60}")

print("\nDetailed Classification Report:")
print(classification_report(
    y_test, y_pred,
    target_names=['Healthy', 'Voltage Unbalance', 'Rotor Fault', 'Stator Fault'],
    digits=3
))

# Per-class accuracy
print("Per-class Accuracy:")
for lbl, name in enumerate(['Healthy', 'Voltage Unbalance', 'Rotor Fault', 'Stator Fault']):
    mask     = y_test == lbl
    cls_acc  = accuracy_score(y_test[mask], y_pred[mask]) * 100
    print(f"  {name:<22}: {cls_acc:.2f}%")

# Feature importance
print("\nTop 10 Most Important Features:")
importances = model.feature_importances_
indices     = np.argsort(importances)[::-1]
for rank in range(min(10, len(feature_cols))):
    i = indices[rank]
    print(f"  {rank+1:2d}. {feature_cols[i]:<25} {importances[i]:.4f}")

# ===== STEP 6: SAVE MODEL =====
print("\n" + "=" * 60)
print("SAVING MODEL...")
print("=" * 60)

joblib.dump(model,        MODEL_OUT)
joblib.dump(feature_cols, FEATURES_OUT)

print(f"✅ Model saved    : {MODEL_OUT}")
print(f"✅ Features saved : {FEATURES_OUT}")
print(f"   Model trained on {len(feature_cols)} features — matches dashboard.py ✓")

# ===== STEP 7: CONFUSION MATRIX PLOT =====
print("\n" + "=" * 60)
print("SAVING CONFUSION MATRIX...")
print("=" * 60)

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(10, 8))
sns.heatmap(
    cm, annot=True, fmt='d', cmap='Blues',
    xticklabels=['Healthy', 'V.Unbal', 'Rotor', 'Stator'],
    yticklabels=['Healthy', 'V.Unbal', 'Rotor', 'Stator'],
    cbar_kws={'label': 'Count'},
    annot_kws={'size': 14, 'weight': 'bold'}
)
plt.title(f'Confusion Matrix\nAccuracy: {accuracy:.2f}%',
          fontsize=16, fontweight='bold', pad=20)
plt.ylabel('True Label',     fontsize=12, fontweight='bold')
plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')
plt.tight_layout()
plt.savefig('ml_results.png', dpi=300, bbox_inches='tight')
plt.show()
print("✅ Confusion matrix saved: ml_results.png")

# ===== FINAL SUMMARY =====
print("\n" + "=" * 60)
print("TRAINING COMPLETE!")
print("=" * 60)
print(f"\n  Total recordings : {len(df):,}")
print(f"  Features used    : {len(feature_cols)} (same as dashboard)")
print(f"  Model accuracy   : {accuracy:.2f}%")
print(f"\n  Files created:")
print(f"    ml_model.pkl   — trained classifier")
print(f"    features.pkl   — feature name list")
print(f"    ml_results.png — confusion matrix")
print(f"\n  Next step:")
print(f"    streamlit run dashboard.py")
print("=" * 60)